{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible uses of the `pipeline`\n",
    "- `audio-classification`: will return a AudioClassification Pipeline.\n",
    "- `automatic-speech-recognition`: will return a AutomaticSpeechRecognition Pipeline.\n",
    "- `conversational`: will return a ConversationalPipeline.\n",
    "- `feature-extraction`: will return a FeatureExtractionPipeline.\n",
    "- `fill-mask`: will return a FillMaskPipeline:.\n",
    "- `image-classification`: will return a ImageClassification Pipeline.\n",
    "- `question-answering`: will return a QuestionAnsweringPipeline.\n",
    "- `table-question-answering`: will return a TableQuestionAnsweringPipeline.\n",
    "- `textitext-generation`: will return a Text2TextGeneration Pipeline.\n",
    "- `text-classification` (alias `sentiment-analysis` available): will return a\n",
    "- TextClassification Pipeline.\n",
    "- `text-generation`: will return a TextGeneration Pipeline:\n",
    "- `token-classification` (alias `ner` available): will return a TokenClassificationPipeline.\n",
    "- `translation`: will return a TranslationPipeline.\n",
    "- `translation _xx_to_yy`: will return a Translation Pipeline.\n",
    "- `summarization`: will return a Summarization Pipeline.\n",
    "- `zero-shot-classification`: will return a ZeroShotClassificationPipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/news/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9954741597175598}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "res = classifier(\"I really can't wait for today's class\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow duck likes to swim, but the yellow duck doesn't like to get wet . But always it chooses to towel off\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "### SUMMARIZER\n",
    "#   identify the model \n",
    "summarization_model_name = \"Falconsai/text_summarization\"\n",
    "#   instantiate the tokenizer for this model\n",
    "summarization_tokenizer = AutoTokenizer.from_pretrained(summarization_model_name)\n",
    "#   combine into a classifier\n",
    "summarizer = pipeline(\"summarization\", model=summarization_model_name, tokenizer=summarization_tokenizer)\n",
    "# call like sentiment_classifier(input)[0]['label']\n",
    "\n",
    "res = summarizer(\"The yellow duck likes to swim, but the yellow duck doesn't like to get wet, so the yellow duck will often wear rain boots when swimming, as well as a rain coat and an umbrella. But always it chooses to towel off after swimming.\", \n",
    "                 max_length=30, min_length=10, do_sample=False)[0]['summary_text']\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'How positive is the following sentence: I like cookies.', 'labels': ['analyzing sentiment task', 'translation task', 'conversational task', 'summarization task'], 'scores': [0.42200323939323425, 0.22456932067871094, 0.20230397582054138, 0.15112346410751343]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "res = classifier(\n",
    "    \"How positive is the following sentence: I like cookies.\",\n",
    "    candidate_labels=['conversational task', 'summarization task', 'translation task', 'analyzing sentiment task'],\n",
    ")\n",
    "print(res)\n",
    "\n",
    "# correspond to these model options ['conversational', 'summarization', 'translation', 'sentiment-analysis'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"conversational\")\n",
    "res = classifier(\n",
    "    \n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Let's show how to specify your own model into a pipeline\n",
    "#   identify the model \n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#   instantiate the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "#   instantiate the tokenizer for this model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#   combine into a classifier\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "res = classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
    "print(res[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lower' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlower\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSITIVE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lower' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Python documentation found for 'lower case string'.\n",
      "Use help() to get the interactive help utility.\n",
      "Use help(str) for help on the str class.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe this is a translation task request\n",
      "I'm going to use the translation model for this\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "### TASK CLASSIFIER\n",
    "task_classifier = pipeline(\"zero-shot-classification\")\n",
    "task_candidate_labels = ['conversational task', 'summarization task', 'translation task', 'analyzing sentiment task']\n",
    "# call like task_classifier(input, candidate_labels=task_candidate_labels)\n",
    "\n",
    "task_switcher = {\n",
    "    'conversational task': 'conversational',\n",
    "    'summarization task' : 'summarization',\n",
    "    'translation task': 'translation',\n",
    "    'analyzing sentiment task': 'sentiment-analysis'\n",
    "}\n",
    "input = \"can you translate from english to german the phrase: hello darkness my old friend\"\n",
    "task_class = task_classifier(input, candidate_labels=task_candidate_labels)['labels'][0]\n",
    "print(f\"I believe this is a {task_class} request\")\n",
    "task = task_switcher[task_class]\n",
    "print(f\"I'm going to use the {task} model for this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
